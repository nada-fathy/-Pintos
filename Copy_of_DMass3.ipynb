{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nada-fathy/-pintOS/blob/master/Copy_of_DMass3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H98tQtLGdcIP",
        "outputId": "1a2e5abf-2579-4be1-a9b3-9f74066122ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNjbkaGsd2Nn",
        "outputId": "784466c8-4f21-4059-8d81-9b4e07b8f004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "import nltk\n",
        "from sklearn import metrics\n",
        "from nltk import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import TextBlob\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5dn7Ud_vd6Z6"
      },
      "outputs": [],
      "source": [
        "def preProcessing(filename):\n",
        "  file = open(filename, 'rt')\n",
        "  text = file.read()\n",
        "  file.close()\n",
        "  # lower cases\n",
        "  text=text.lower()\n",
        "\n",
        "  text =\"\".join([i for i in text if i not in string.punctuation])\n",
        "  # split into sentences\n",
        " \n",
        "  ###sentences = sent_tokenize(text)\n",
        "  #print(sentences[0])\n",
        "\n",
        "  # split into words\n",
        "\n",
        "  tokens = word_tokenize(text)\n",
        "  #print(tokens[:100])\n",
        "\n",
        "  # remove all tokens that are not alphabetic\n",
        "  \n",
        " # words = [word for word in tokens if word.isalpha()]\n",
        " # for word in words:\n",
        " #   word = TextBlob(word).correct()\n",
        "    \n",
        "  #print(words[:100])\n",
        "\n",
        " \n",
        "  #####stop_words = stopwords.words('english')\n",
        "\n",
        "  # filter out stop words\n",
        "  \n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = [w for w in tokens if not w in stop_words]\n",
        "  #print(words[:100])\n",
        "\n",
        "  # stemming of words\n",
        "  \n",
        "  porter = PorterStemmer()\n",
        "  stemmed = [porter.stem(word) for word in words]\n",
        "  #print(stemmed[:100])\n",
        "  #print([' '.join(stemmed)])\n",
        "  return ' '.join(stemmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMXGA1D-eVyB",
        "outputId": "a4df25b2-b920-4404-aef5-4682d7a87240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "12500\n",
            "12500\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# assign directory\n",
        "directory1 = '/content/drive/MyDrive/ca/aclImdb/train/neg'\n",
        "directory2 = '/content/drive/MyDrive/ca/aclImdb/train/pos/'\n",
        "Xtrain=[]\n",
        "Ytrain=[]\n",
        "# iterate over files in\n",
        "# that directory\n",
        "for filename in os.listdir(directory1):\n",
        "    f = os.path.join(directory1, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "      if len(Xtrain)%1000==0:\n",
        "        print(len(Xtrain))\n",
        "      #print(f)\n",
        "      newText=preProcessing(f)\n",
        "        #print(len(Xtrain))\n",
        "        #print(newText)\n",
        "      Xtrain.append(newText)\n",
        "      name, extension = os.path.splitext(filename)\n",
        "      Ytrain.append(int(name[-1]))\n",
        "print(len(Xtrain))\n",
        "print(len(Ytrain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voVSU5XyfwUC",
        "outputId": "fc473a1b-9559-426f-e584-db2870662fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "25000\n"
          ]
        }
      ],
      "source": [
        "for filename in os.listdir(directory2):\n",
        "    f = os.path.join(directory2, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "        #print(f)\n",
        "        if len(Xtrain)%1000==0:\n",
        "          print(len(Xtrain))\n",
        "        newText=preProcessing(f)\n",
        "        #print(len(Xtrain))\n",
        "        #print(newText)\n",
        "        Xtrain.append(newText)\n",
        "        name, extension = os.path.splitext(filename)\n",
        "        Ytrain.append(int(name.split('_')[1]))\n",
        "print(len(Xtrain))\n",
        "print(len(Ytrain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoHltdbl3Xr9",
        "outputId": "002112d1-0aed-4565-d51b-fcaa2715eeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "12500\n",
            "12500\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "25000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# assign directory\n",
        "directory1 = '/content/drive/MyDrive/ca/aclImdb/test/neg/'\n",
        "directory2 = '/content/drive/MyDrive/ca/aclImdb/test/pos/'\n",
        "Xtest=[]\n",
        "Ytest=[]\n",
        "# iterate over files in\n",
        "# that directory\n",
        "for filename in os.listdir(directory1):\n",
        "    f = os.path.join(directory1, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "      if len(Xtest)%1000==0:\n",
        "        print(len(Xtest))\n",
        "      text_file = open(f, \"r\")\n",
        "      newText=text_file.read()\n",
        "      Xtest.append(newText)\n",
        "      name, extension = os.path.splitext(filename)\n",
        "      Ytest.append(int(name[-1]))\n",
        "print(len(Xtest))\n",
        "print(len(Ytest))\n",
        "for filename in os.listdir(directory2):\n",
        "    f = os.path.join(directory2, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "        #print(f)\n",
        "        if len(Xtest)%1000==0:\n",
        "          print(len(Xtest))\n",
        "        text_file = open(f, \"r\")\n",
        "        newText=text_file.read()        \n",
        "        #print(len(Xtrain))\n",
        "        #print(newText)\n",
        "        Xtest.append(newText)\n",
        "        name, extension = os.path.splitext(filename)\n",
        "        Ytest.append(int(name.split('_')[1]))\n",
        "print(len(Xtest))\n",
        "print(len(Ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4UgASXGjkIZa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "Xdf=pd.DataFrame(Xtrain)\n",
        "# print(Xdf)\n",
        "X=Xdf[0]\n",
        "# print(xtrain)\n",
        "# print(Xdf[0])\n",
        "Ydf=pd.DataFrame(Ytrain)\n",
        "Y=Ydf[0]\n",
        "#x_train, x_dev, y_train, y_dev = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [2,4]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhc2ASdFYYaI",
        "outputId": "8f47a326-7ef6-44da-9797-2f0ca21a3fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [10, 17, 25, 33, 41, 48, 56, 64, 72, 80], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 4], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'bootstrap': [True, False]}\n"
          ]
        }
      ],
      "source": [
        "# Create the param grid\n",
        "param_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(param_grid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3RCmmmh9riV"
      },
      "outputs": [],
      "source": [
        "################################\n",
        "def solveSVM(x_train, x_dev, y_train, y_dev):\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "  from sklearn.pipeline import Pipeline\n",
        "  from sklearn.svm import LinearSVC\n",
        "  from sklearn import metrics\n",
        "  text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                      ('clf', LinearSVC()),])\n",
        "  text_clf.fit(x_train, y_train)  \n",
        "  predictions = text_clf.predict(x_dev)\n",
        "  print(metrics.classification_report(y_dev,predictions)) \n",
        "  print(metrics.accuracy_score(y_dev,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHcNUyiK7LFT",
        "outputId": "cd29124a-5c47-41a5-f740-04c6646170b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.57      0.74      0.65       509\n",
            "           2       0.30      0.17      0.22       239\n",
            "           3       0.24      0.18      0.21       256\n",
            "           4       0.35      0.30      0.32       294\n",
            "           7       0.31      0.29      0.30       253\n",
            "           8       0.31      0.30      0.30       285\n",
            "           9       0.25      0.17      0.20       219\n",
            "          10       0.48      0.64      0.55       445\n",
            "\n",
            "    accuracy                           0.41      2500\n",
            "   macro avg       0.35      0.35      0.34      2500\n",
            "weighted avg       0.39      0.41      0.39      2500\n",
            "\n",
            "0.414\n"
          ]
        }
      ],
      "source": [
        "#################################\n",
        "solveSVM(x_train, x_dev, y_train, y_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "m8py1Bi6TlfE"
      },
      "outputs": [],
      "source": [
        "\n",
        "def solveRandomforest(x_train, x_dev, y_train, y_dev):\n",
        "\n",
        "  from sklearn.model_selection import RandomizedSearchCV\n",
        "  rf_model=RandomForestClassifier()\n",
        "  #rf_RandomGrid = RandomizedSearchCV(estimator = rf_Model, param_distributions = param_grid, cv = 10, verbose=2, n_jobs = 4)\n",
        "  text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                       ('clf',RandomizedSearchCV(estimator = rf_model, param_distributions = param_grid, cv = 10, verbose=2, n_jobs = 4)),])\n",
        "                     # ('clf', RandomForestClassifier(n_estimators=200, random_state=0)),])\n",
        "  \n",
        "  #rf_Grid = GridSearchCV(estimator =rf_model, param_grid = param_grid, cv = 10, verbose=2, n_jobs = 4)\n",
        "  text_clf.fit(x_train, y_train)  \n",
        "  \n",
        "  #rf_Grid.best_params_\n",
        "  #rf_RandomGrid.best_params_\n",
        "  predictions = text_clf.predict(x_dev)\n",
        "  print(metrics.classification_report(y_dev,predictions)) \n",
        "  print(\"Accuracy:\",metrics.accuracy_score(y_dev,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIwgA49vUV_m",
        "outputId": "3a1dd02b-29bf-4e27-f139-93c0a2065fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.40      0.00      0.00      5022\n",
            "           2       0.00      0.00      0.00      2302\n",
            "           3       0.00      0.00      0.00      2541\n",
            "           4       0.00      0.00      0.00      2635\n",
            "           7       0.00      0.00      0.00      2307\n",
            "           8       0.00      0.00      0.00      2850\n",
            "           9       0.00      0.00      0.00      2344\n",
            "          10       0.20      1.00      0.33      4999\n",
            "\n",
            "    accuracy                           0.20     25000\n",
            "   macro avg       0.08      0.13      0.04     25000\n",
            "weighted avg       0.12      0.20      0.07     25000\n",
            "\n",
            "Accuracy: 0.20004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "solveRandomforest(Xtrain, Xtest, Ytrain, Ytest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEkazNV3cIYp"
      },
      "outputs": [],
      "source": [
        "################################\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "#count_vect = CountVectorizer()\n",
        "\n",
        "#X_train_counts = count_vect.fit_transform(Xtrain)\n",
        "#from sklearn.feature_extraction.text import TfidfTransformer\n",
        "#tfidf_transformer = TfidfTransformer()\n",
        "#X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(Xtrain) # remember to use the original X_train set\n",
        "X_train_tfidf.shape\n",
        "\n",
        "X_test_tfidf = vectorizer.fit_transform(Xtest) # remember to use the original X_train set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LWQAZYGVmWf"
      },
      "outputs": [],
      "source": [
        "#def solveRandomforest2(x_train, x_test, y_train, y_test):\n",
        "\n",
        " # from sklearn.model_selection import RandomizedSearchCV\n",
        "  #rf_model=RandomForestClassifier()\n",
        "  #rf_RandomGrid = RandomizedSearchCV(estimator = rf_model, param_distributions = param_grid, cv = 10, verbose=2, n_jobs = 4)\n",
        "  #####text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                     #####('clf',RandomizedSearchCV(estimator = rf_model, param_distributions = param_grid, cv = 10, verbose=2, n_jobs = 4)),])\n",
        "                     ####('clf', RandomForestClassifier(n_estimators=200, random_state=0)),])\n",
        "  \n",
        " ###### #rf_Grid = GridSearchCV(estimator =rf_model, param_grid = param_grid, cv = 10, verbose=2, n_jobs = 4)\n",
        "  #rf_RandomGrid.fit(x_train, y_train)  \n",
        "  \n",
        "  #####rf_Grid.best_params_\n",
        "  #rf_RandomGrid.best_params_\n",
        "  #print (f'Train Accuracy - : {rf_RandomGrid.score(x_train,y_train):.3f}')\n",
        "  #print (f'Test Accuracy - : {rf_RandomGrid.score(x_test,y_test):.3f}')\n",
        "#solveRandomforest2(X_train_tfidf, Xtest, Ytrain, Ytest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Nno3Ey6fxlf"
      },
      "outputs": [],
      "source": [
        "###################################################\n",
        "\n",
        "param_grid = [    \n",
        "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'C' : np.logspace(-4, 4, 20),\n",
        "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
        "    'max_iter' : [100, 1000,2500, 5000]\n",
        "    }\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6Soi-ksnY6qC"
      },
      "outputs": [],
      "source": [
        "param_grid = [    \n",
        "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'C' : np.logspace(-4, 4, 20),\n",
        "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
        "    'max_iter' : [100, 1000,2500, 5000]\n",
        "    }\n",
        "]\n",
        "\n",
        "def LogesticRegression(x_train,y_train,x_test,y_test):\n",
        "  from sklearn.model_selection import RandomizedSearchCV\n",
        "  rf_model=LogisticRegression()\n",
        "  #rf_RandomGrid = RandomizedSearchCV(estimator = rf_Model, param_distributions = param_grid, cv = 10, verbose=2, n_jobs = 4)\n",
        "  text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                       ('clf',RandomizedSearchCV(estimator = rf_model, param_distributions = param_grid, cv = 10, verbose=2, n_jobs = 1)),])\n",
        "                     # ('clf', RandomForestClassifier(n_estimators=200, random_state=0)),])\n",
        "  \n",
        "  #rf_Grid = GridSearchCV(estimator =rf_model, param_grid = param_grid, cv = 10, verbose=2, n_jobs = 4)\n",
        "  text_clf.fit(x_train, y_train)  \n",
        "  \n",
        "  #rf_Grid.best_params_\n",
        "  #rf_RandomGrid.best_params_\n",
        "  predictions = text_clf.predict(x_test)\n",
        "  print(metrics.classification_report(y_test,predictions)) \n",
        "  print(\"Accuracy:\",metrics.accuracy_score(y_test,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSDXJNX_ezSM",
        "outputId": "60c3abc6-2a92-4c4f-eb60-2a10cf5da01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
            "[CV] END C=0.0001, max_iter=2500, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=545.5594781168514, max_iter=1000, penalty=l2, solver=lbfgs; total time= 4.3min\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=1000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  48.2s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  50.1s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  46.6s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  45.7s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  43.4s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  47.8s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  46.1s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  45.9s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  44.0s\n",
            "[CV] END C=29.763514416313132, max_iter=5000, penalty=l2, solver=newton-cg; total time=  42.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=11.288378916846883, max_iter=100, penalty=none, solver=newton-cg; total time= 1.2min\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END ...C=10000.0, max_iter=5000, penalty=l1, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=0.23357214690901212, max_iter=5000, penalty=elasticnet, solver=sag; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=78.47599703514607, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
            "[CV] END C=0.012742749857031334, max_iter=2500, penalty=elasticnet, solver=liblinear; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 2.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 1.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0.012742749857031334, max_iter=100, penalty=none, solver=newton-cg; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "60 fits failed out of a total of 100.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "20 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 459, in _check_solver\n",
            "    solver\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [    nan 0.37268     nan 0.38804 0.36456     nan     nan     nan     nan\n",
            " 0.36456]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.62      0.13      0.22      5022\n",
            "           2       0.13      0.35      0.19      2302\n",
            "           3       0.16      0.01      0.02      2541\n",
            "           4       0.22      0.00      0.01      2635\n",
            "           7       0.13      0.47      0.20      2307\n",
            "           8       0.16      0.20      0.17      2850\n",
            "           9       0.13      0.00      0.01      2344\n",
            "          10       0.33      0.37      0.35      4999\n",
            "\n",
            "    accuracy                           0.20     25000\n",
            "   macro avg       0.24      0.19      0.15     25000\n",
            "weighted avg       0.28      0.20      0.17     25000\n",
            "\n",
            "Accuracy: 0.20072\n"
          ]
        }
      ],
      "source": [
        "\n",
        "LogesticRegression(Xtrain, Ytrain, Xtest,  Ytest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkJ8fZpXfad9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6cxGL5_X915J"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1],\n",
        "              'gamma': [1],\n",
        "              'kernel': ['rbf']}\n",
        "def solveSVM(x_train, x_dev, y_train, y_dev):\n",
        "  \n",
        "  text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                      ('clf', GridSearchCV(SVC(), param_grid, refit = True, cv = 10, verbose = 3)),])\n",
        "  text_clf.fit(x_train, y_train)  \n",
        "  \n",
        "  #rf_Grid.best_params_\n",
        "  #rf_RandomGrid.best_params_\n",
        "  predictions = text_clf.predict(x_dev)\n",
        "  print(metrics.classification_report(y_dev,predictions)) \n",
        "  print(\"Accuracy:\",metrics.accuracy_score(y_dev,predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR9RMZ05-61T",
        "outputId": "79a8a8d7-19a8-408e-90d7-60aa66cfd66f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "[CV 1/10] END .......C=0.1, gamma=1, kernel=rbf;, score=0.340 total time=17.1min\n",
            "[CV 2/10] END .......C=0.1, gamma=1, kernel=rbf;, score=0.347 total time=18.5min\n",
            "[CV 3/10] END .......C=0.1, gamma=1, kernel=rbf;, score=0.344 total time=17.7min\n",
            "[CV 4/10] END .......C=0.1, gamma=1, kernel=rbf;, score=0.350 total time=18.6min\n",
            "[CV 5/10] END .......C=0.1, gamma=1, kernel=rbf;, score=0.346 total time=17.0min\n",
            "[CV 6/10] END .......C=0.1, gamma=1, kernel=rbf;, score=0.336 total time=16.7min\n",
            "[CV 7/10] END .......C=0.1, gamma=1, kernel=rbf;, score=0.340 total time=16.9min\n",
            "[CV 8/10] END .......C=0.1, gamma=1, kernel=rbf;, score=0.341 total time=17.1min\n",
            "[CV 9/10] END .......C=0.1, gamma=1, kernel=rbf;, score=0.344 total time=17.3min\n",
            "[CV 10/10] END ......C=0.1, gamma=1, kernel=rbf;, score=0.340 total time=18.5min\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.68      0.05      0.10      5022\n",
            "           2       0.00      0.00      0.00      2302\n",
            "           3       0.00      0.00      0.00      2541\n",
            "           4       0.00      0.00      0.00      2635\n",
            "           7       0.00      0.00      0.00      2307\n",
            "           8       0.00      0.00      0.00      2850\n",
            "           9       0.00      0.00      0.00      2344\n",
            "          10       0.20      1.00      0.34      4999\n",
            "\n",
            "    accuracy                           0.21     25000\n",
            "   macro avg       0.11      0.13      0.05     25000\n",
            "weighted avg       0.18      0.21      0.09     25000\n",
            "\n",
            "Accuracy: 0.2106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "solveSVM(Xtrain, Xtest, Ytrain,  Ytest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ypalbvz_H1t"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of DMass3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}